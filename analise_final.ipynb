{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DADOS DOS IDOSOS\n",
    "---\n",
    "\n",
    "Em resumo, antes de tudo:\n",
    "1. Precisamos conhecer o contexto dos nossos dados\n",
    "2. Precisamos saber qual a finalidade do trabalho\n",
    "3. Precisamos conhecer o business que estamos trabalhando\n",
    "4. Elaborar hipóteses\n",
    "\n",
    "Após estes processos, nós iniciaremos nossa analise exploratória dos dados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Conhecendo o contexto dos nossos dados\n",
    "---\n",
    "\n",
    "**Idade**: Está em dado contínuo (Parece que foi importante na Análise do Renan);  \n",
    "**Sexo**: 1 para feminino e 2 para masculino;  \n",
    "**Comorbidade**: Número de comorbidades;  \n",
    "**Escolaridade**: Classificação (0 para analfabeto; 1 para dois a quatro anos de estudo; 2 para cinco a oito anos de estudo; 3 para nove a doze anos de estudo; 4 para mais de doze anos );  \n",
    "**Diagnóstico**: 1 grupo de controle; 2 comprometimento cognitivo leve; 3 doença de alzheimer  \n",
    "**Handgrip**: (Aparelho usado exercitar a musculatura, precisão motora e a força das mãos?): Está em Kg/Força, teste motor  \n",
    "**IADL**: (Atividades Instrumentais de Vida Diária): 1 para disfuncional e 2 para funcional (a confirmar), teste funcional  \n",
    "**BBS**: (Escala de Equilíbrio de Berg): Por pontuação (score varia de 0 - 56), teste motor  \n",
    "**STS**: (Teste de Sentar e Levantar): Número de vezes que a pessoa senta e levanta da cadeira, teste motor  \n",
    "**GSST**: (Velocidade da marcha em tarefas simples): velocidade em m/s, teste motor-cognitivo  \n",
    "**GSDT**: (Velocidade da marcha em dupla tarefa): velocidade em m/s, teste motor-cognitivo  \n",
    "**Delta GS**: (Subtração entre o GSST e GSDT) teste motor-cognitivo  \n",
    "**DTC**: (Custo da dupla tarefa/dual task cost): em %, teste motor-cognitivo  \n",
    "**STEP**: (número de repetições): Quantidade, teste motor  \n",
    "**FMTIT**: (Tempo do Floor Maze imediato): tempo em segundos, teste cognitivo  \n",
    "**FMTDT**: (Tempo do Floor Maze posterior): tempo em segundos, teste cognitivo  \n",
    "**MMSE**: (Minimental): Pontuação ( 25 pontos ou mais é normal, entre 21-24 tem perda cognitiva leve, entre 10-20 é moderada e 9 ou menos é grave), teste cognitivo  \n",
    "**CDT**: (Teste de relógio): Pontuação em erros (Entre 0 e 3: 0 erros, 3 erros, etc...), teste motor  \n",
    "**TMTA**: (Teste de Atenção): Tempo em segundos, teste cognitivo  \n",
    "**DSF**: (Digit Span Forward): Por pontuação, teste cognitivo  \n",
    "**DSB**: (Digit Span Backwards): Por pontuação, teste cognitivo  \n",
    "**VF**: (Fluência verbal): Número de Palavras, teste cognitivo  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Qual a finalidade do trabalho?\n",
    "---\n",
    "\n",
    "Este trabalho tem a finalidade de descobrir quais são as **variáveis mais relevantes** para classificar os idosos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Conhecendo o business\n",
    "---\n",
    "\n",
    "### O que é a doença de Alzheimer?\n",
    "\n",
    "A Doença de Alzheimer (DA) é um transtorno neurodegenerativo progressivo e fatal que se manifesta pela deterioração cognitiva e da memória, comprometimento progressivo das atividades de vida diária e uma variedade de sintomas neuropsiquiátricos e de alterações comportamentais. A doença instala-se quando o processamento de certas proteínas do sistema nervoso central começa a dar errado. Surgem, então, fragmentos de proteínas mal cortadas, tóxicas, dentro dos neurônios e nos espaços que existem entre eles. Como consequência dessa toxicidade, ocorre perda progressiva de neurônios em certas regiões do cérebro, como o hipocampo, que controla a memória, e o córtex cerebral, essencial para a linguagem e o raciocínio, memória, reconhecimento de estímulos sensoriais e pensamento abstrato.\n",
    "\n",
    "A Doença de Alzheimer é a forma mais comum de demência neurodegenerativa em pessoas de idade, sendo responsável por mais da metade dos casos de demência nessa população.\n",
    "\n",
    "### Estágios\n",
    "\n",
    "**O quadro clínico costuma ser dividido em quatro estágios**:\n",
    "\n",
    "- Estágio 1 (forma inicial): alterações na memória, na personalidade e nas habilidades visuais e espaciais;\n",
    "- Estágio 2 (forma moderada): dificuldade para falar, realizar tarefas simples e coordenar movimentos. Agitação e insônia;\n",
    "- Estágio 3 (forma grave): resistência à execução de tarefas diárias. Incontinência urinária e fecal. Dificuldade para comer. Deficiência motora progressiva;\n",
    "- Estágio 4 (terminal): restrição ao leito. Mutismo. Dor à deglutição. Infecções intercorrentes.\n",
    "\n",
    "### Sintomas\n",
    "\n",
    "**Entre os principais sinais e sintomas do Alzheimer estão**:\n",
    "\n",
    "- Falta de memória para acontecimentos recentes;\n",
    "- Repetição da mesma pergunta várias vezes;\n",
    "- Dificuldade para acompanhar conversações ou pensamentos complexos;\n",
    "- Incapacidade de elaborar estratégias para resolver problemas;\n",
    "- Dificuldade para dirigir automóvel e encontrar caminhos conhecidos;\n",
    "- Dificuldade para encontrar palavras que exprimam ideias ou sentimentos pessoais;\n",
    "- Irritabilidade, suspeição injustificada, agressividade, passividade, interpretações erradas de estímulos visuais ou auditivos, tendência ao isolamento.\n",
    "\n",
    "### Fatores de risco\n",
    "\n",
    "**Alguns fatores de risco para o Alzheimer são**:\n",
    "\n",
    "- A idade e a história familiar: a demência é mais provável se a pessoa tem algum familiar que já sofreu do problema;\n",
    "- Baixo nível de escolaridade: pessoas com maior nível de escolaridade geralmente executam atividades intelectuais mais complexas, que oferecem uma maior quantidade de estímulos cerebrais.\n",
    "\n",
    "Fonte: https://www.gov.br/saude/pt-br/assuntos/saude-de-a-a-z/a/alzheimer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando arquivos e packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizacao\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# manipulaca dos dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# machine learning e estatística\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnoses</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Comorbidities</th>\n",
       "      <th>Scholarity</th>\n",
       "      <th>Handgrip</th>\n",
       "      <th>IADL</th>\n",
       "      <th>BBS</th>\n",
       "      <th>STS</th>\n",
       "      <th>GSST</th>\n",
       "      <th>GSDT</th>\n",
       "      <th>delta GS</th>\n",
       "      <th>DTC</th>\n",
       "      <th>STEP</th>\n",
       "      <th>FMTIT</th>\n",
       "      <th>FMTDT</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>CDT</th>\n",
       "      <th>TMTA</th>\n",
       "      <th>DSF</th>\n",
       "      <th>DSB</th>\n",
       "      <th>VF</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.381930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.831919</td>\n",
       "      <td>0.735736</td>\n",
       "      <td>0.096183</td>\n",
       "      <td>11.561562</td>\n",
       "      <td>82.0</td>\n",
       "      <td>18.42</td>\n",
       "      <td>13.28</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.26</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.588638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.818030</td>\n",
       "      <td>0.782748</td>\n",
       "      <td>0.035282</td>\n",
       "      <td>4.313099</td>\n",
       "      <td>102.0</td>\n",
       "      <td>22.60</td>\n",
       "      <td>13.84</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.67</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69.659138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.822148</td>\n",
       "      <td>0.705036</td>\n",
       "      <td>0.117112</td>\n",
       "      <td>14.244604</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.75</td>\n",
       "      <td>11.42</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.991102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.955166</td>\n",
       "      <td>0.829103</td>\n",
       "      <td>0.126062</td>\n",
       "      <td>13.197970</td>\n",
       "      <td>122.0</td>\n",
       "      <td>19.34</td>\n",
       "      <td>14.43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>56.84</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>82.469541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.917603</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.188436</td>\n",
       "      <td>20.535714</td>\n",
       "      <td>109.0</td>\n",
       "      <td>11.30</td>\n",
       "      <td>10.37</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.49</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Diagnoses  Sex        Age  Comorbidities  Scholarity  Handgrip  IADL  \\\n",
       "0          1.0  1.0  74.381930            0.0         4.0      24.4   1.0   \n",
       "1          1.0  1.0  72.588638            0.0         3.0      22.8   1.0   \n",
       "2          1.0  2.0  69.659138            0.0         3.0      57.2   1.0   \n",
       "3          1.0  2.0  72.991102            0.0         NaN      45.8   2.0   \n",
       "4          1.0  2.0  82.469541            0.0         4.0      31.4   1.0   \n",
       "..         ...  ...        ...            ...         ...       ...   ...   \n",
       "268        NaN  NaN        NaN            NaN         NaN       NaN   NaN   \n",
       "269        NaN  NaN        NaN            NaN         NaN       NaN   NaN   \n",
       "270        NaN  NaN        NaN            NaN         NaN       NaN   NaN   \n",
       "271        NaN  NaN        NaN            NaN         NaN       NaN   NaN   \n",
       "272        NaN  NaN        NaN            NaN         NaN       NaN   NaN   \n",
       "\n",
       "      BBS   STS      GSST      GSDT  delta GS        DTC   STEP  FMTIT  FMTDT  \\\n",
       "0    56.0  15.0  0.831919  0.735736  0.096183  11.561562   82.0  18.42  13.28   \n",
       "1    55.0  16.0  0.818030  0.782748  0.035282   4.313099  102.0  22.60  13.84   \n",
       "2    56.0  11.0  0.822148  0.705036  0.117112  14.244604   93.0  14.75  11.42   \n",
       "3    56.0  16.0  0.955166  0.829103  0.126062  13.197970  122.0  19.34  14.43   \n",
       "4    55.0  14.0  0.917603  0.729167  0.188436  20.535714  109.0  11.30  10.37   \n",
       "..    ...   ...       ...       ...       ...        ...    ...    ...    ...   \n",
       "268   NaN   NaN       NaN       NaN       NaN        NaN    NaN    NaN    NaN   \n",
       "269   NaN   NaN       NaN       NaN       NaN        NaN    NaN    NaN    NaN   \n",
       "270   NaN   NaN       NaN       NaN       NaN        NaN    NaN    NaN    NaN   \n",
       "271   NaN   NaN       NaN       NaN       NaN        NaN    NaN    NaN    NaN   \n",
       "272   NaN   NaN       NaN       NaN       NaN        NaN    NaN    NaN    NaN   \n",
       "\n",
       "     MMSE  CDT   TMTA  DSF  DSB    VF  Unnamed: 22  \n",
       "0    29.0  3.0  46.26  7.0  6.0  13.0          NaN  \n",
       "1    29.0  3.0  51.67  9.0  5.0  12.0          NaN  \n",
       "2    26.0  3.0  72.26  5.0  4.0  18.0          NaN  \n",
       "3    29.0  3.0  56.84  5.0  5.0  23.0          NaN  \n",
       "4    28.0  3.0  49.49  7.0  8.0  20.0          NaN  \n",
       "..    ...  ...    ...  ...  ...   ...          ...  \n",
       "268   NaN  NaN    NaN  NaN  NaN   NaN          NaN  \n",
       "269   NaN  NaN    NaN  NaN  NaN   NaN          NaN  \n",
       "270   NaN  NaN    NaN  NaN  NaN   NaN          NaN  \n",
       "271   NaN  NaN    NaN  NaN  NaN   NaN          NaN  \n",
       "272   NaN  NaN    NaN  NaN  NaN   NaN          NaN  \n",
       "\n",
       "[273 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = pd.read_excel(\"Planilha de dados_projetoexercicio_031122.xlsx\")\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 273 entries, 0 to 272\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Diagnoses      109 non-null    float64\n",
      " 1   Sex            109 non-null    float64\n",
      " 2   Age            109 non-null    float64\n",
      " 3   Comorbidities  99 non-null     float64\n",
      " 4   Scholarity     105 non-null    float64\n",
      " 5   Handgrip       100 non-null    float64\n",
      " 6   IADL           105 non-null    float64\n",
      " 7   BBS            109 non-null    float64\n",
      " 8   STS            109 non-null    float64\n",
      " 9   GSST           109 non-null    float64\n",
      " 10  GSDT           109 non-null    float64\n",
      " 11  delta GS       109 non-null    float64\n",
      " 12  DTC            109 non-null    float64\n",
      " 13  STEP           109 non-null    float64\n",
      " 14  FMTIT          109 non-null    float64\n",
      " 15  FMTDT          109 non-null    float64\n",
      " 16  MMSE           109 non-null    float64\n",
      " 17  CDT            102 non-null    float64\n",
      " 18  TMTA           105 non-null    float64\n",
      " 19  DSF            108 non-null    float64\n",
      " 20  DSB            108 non-null    float64\n",
      " 21  VF             106 non-null    float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 47.0 KB\n"
     ]
    }
   ],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a coluna \"Unnamed: 22\" tem apenas valores nulos, vamos remove-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnoses</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Comorbidities</th>\n",
       "      <th>Scholarity</th>\n",
       "      <th>Handgrip</th>\n",
       "      <th>IADL</th>\n",
       "      <th>BBS</th>\n",
       "      <th>STS</th>\n",
       "      <th>GSST</th>\n",
       "      <th>GSDT</th>\n",
       "      <th>delta GS</th>\n",
       "      <th>DTC</th>\n",
       "      <th>STEP</th>\n",
       "      <th>FMTIT</th>\n",
       "      <th>FMTDT</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>CDT</th>\n",
       "      <th>TMTA</th>\n",
       "      <th>DSF</th>\n",
       "      <th>DSB</th>\n",
       "      <th>VF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.381930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.831919</td>\n",
       "      <td>0.735736</td>\n",
       "      <td>0.096183</td>\n",
       "      <td>11.561562</td>\n",
       "      <td>82.0</td>\n",
       "      <td>18.42</td>\n",
       "      <td>13.28</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.26</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.588638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.818030</td>\n",
       "      <td>0.782748</td>\n",
       "      <td>0.035282</td>\n",
       "      <td>4.313099</td>\n",
       "      <td>102.0</td>\n",
       "      <td>22.60</td>\n",
       "      <td>13.84</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.67</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69.659138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.822148</td>\n",
       "      <td>0.705036</td>\n",
       "      <td>0.117112</td>\n",
       "      <td>14.244604</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.75</td>\n",
       "      <td>11.42</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.991102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.955166</td>\n",
       "      <td>0.829103</td>\n",
       "      <td>0.126062</td>\n",
       "      <td>13.197970</td>\n",
       "      <td>122.0</td>\n",
       "      <td>19.34</td>\n",
       "      <td>14.43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>56.84</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>82.469541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.917603</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.188436</td>\n",
       "      <td>20.535714</td>\n",
       "      <td>109.0</td>\n",
       "      <td>11.30</td>\n",
       "      <td>10.37</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.49</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.136893</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.921659</td>\n",
       "      <td>0.569260</td>\n",
       "      <td>0.352399</td>\n",
       "      <td>38.235294</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.62</td>\n",
       "      <td>34.35</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.126626</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.722022</td>\n",
       "      <td>0.426136</td>\n",
       "      <td>0.295885</td>\n",
       "      <td>40.980114</td>\n",
       "      <td>57.0</td>\n",
       "      <td>22.60</td>\n",
       "      <td>35.99</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.524983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.433213</td>\n",
       "      <td>0.345821</td>\n",
       "      <td>0.087392</td>\n",
       "      <td>20.172911</td>\n",
       "      <td>43.0</td>\n",
       "      <td>194.50</td>\n",
       "      <td>268.14</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.995893</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.785340</td>\n",
       "      <td>0.021111</td>\n",
       "      <td>2.617801</td>\n",
       "      <td>99.0</td>\n",
       "      <td>84.74</td>\n",
       "      <td>281.31</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.90</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.386721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.785340</td>\n",
       "      <td>0.605449</td>\n",
       "      <td>0.179891</td>\n",
       "      <td>22.906155</td>\n",
       "      <td>56.0</td>\n",
       "      <td>20.22</td>\n",
       "      <td>40.02</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Diagnoses  Sex        Age  Comorbidities  Scholarity  Handgrip  IADL  \\\n",
       "0          1.0  1.0  74.381930            0.0         4.0      24.4   1.0   \n",
       "1          1.0  1.0  72.588638            0.0         3.0      22.8   1.0   \n",
       "2          1.0  2.0  69.659138            0.0         3.0      57.2   1.0   \n",
       "3          1.0  2.0  72.991102            0.0         NaN      45.8   2.0   \n",
       "4          1.0  2.0  82.469541            0.0         4.0      31.4   1.0   \n",
       "..         ...  ...        ...            ...         ...       ...   ...   \n",
       "104        3.0  2.0  72.136893            2.0         3.0      36.7   2.0   \n",
       "105        3.0  2.0  75.126626            2.0         2.0      35.2   2.0   \n",
       "106        3.0  1.0  81.524983            0.0         2.0      22.0   2.0   \n",
       "107        3.0  2.0  77.995893            4.0         3.0      27.7   2.0   \n",
       "108        3.0  2.0  87.386721            NaN         3.0      22.8   2.0   \n",
       "\n",
       "      BBS   STS      GSST      GSDT  delta GS        DTC   STEP   FMTIT  \\\n",
       "0    56.0  15.0  0.831919  0.735736  0.096183  11.561562   82.0   18.42   \n",
       "1    55.0  16.0  0.818030  0.782748  0.035282   4.313099  102.0   22.60   \n",
       "2    56.0  11.0  0.822148  0.705036  0.117112  14.244604   93.0   14.75   \n",
       "3    56.0  16.0  0.955166  0.829103  0.126062  13.197970  122.0   19.34   \n",
       "4    55.0  14.0  0.917603  0.729167  0.188436  20.535714  109.0   11.30   \n",
       "..    ...   ...       ...       ...       ...        ...    ...     ...   \n",
       "104  55.0  12.0  0.921659  0.569260  0.352399  38.235294   71.0   70.62   \n",
       "105  56.0  11.0  0.722022  0.426136  0.295885  40.980114   57.0   22.60   \n",
       "106  53.0   5.0  0.433213  0.345821  0.087392  20.172911   43.0  194.50   \n",
       "107  56.0  10.0  0.806452  0.785340  0.021111   2.617801   99.0   84.74   \n",
       "108  50.0   4.0  0.785340  0.605449  0.179891  22.906155   56.0   20.22   \n",
       "\n",
       "      FMTDT  MMSE  CDT    TMTA   DSF  DSB    VF  \n",
       "0     13.28  29.0  3.0   46.26   7.0  6.0  13.0  \n",
       "1     13.84  29.0  3.0   51.67   9.0  5.0  12.0  \n",
       "2     11.42  26.0  3.0   72.26   5.0  4.0  18.0  \n",
       "3     14.43  29.0  3.0   56.84   5.0  5.0  23.0  \n",
       "4     10.37  28.0  3.0   49.49   7.0  8.0  20.0  \n",
       "..      ...   ...  ...     ...   ...  ...   ...  \n",
       "104   34.35  20.0  0.0  181.00   8.0  3.0   9.0  \n",
       "105   35.99  22.0  2.0   99.03   5.0  2.0  15.0  \n",
       "106  268.14  24.0  1.0  181.00   6.0  4.0   8.0  \n",
       "107  281.31  21.0  2.0   42.90   7.0  2.0  11.0  \n",
       "108   40.02  27.0  3.0   66.00  10.0  7.0   7.0  \n",
       "\n",
       "[109 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = dados.loc[:108, \"Diagnoses\":\"VF\"]\n",
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalonando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_numericos = ['Age', 'Handgrip', 'BBS', 'STS', 'GSST', 'GSDT', 'delta GS', 'DTC', 'STEP', 'FMTIT', 'FMTDT', 'VF', 'TMTA', 'MMSE', 'DSB', 'DSF']\n",
    "dados_categoricos = ['Sex', 'Comorbidities', 'Scholarity', 'IADL', 'CDT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo em vista que, os dados categóricos serão escalonados segundo o método One-Hot-Encode, assumindo os valores 0 ou 1, decidi aplicar o método MinMaxScaler. Dado que, no MinMaxScaler os valores ficarão entre os limites de 0 até 1, então os valores dos dados categóricos pré-processados não estarão muito distantes dos valores dos dados numéricos pré-processados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando o MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definindo o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessador_num = MinMaxScaler().fit(dados[dados_numericos])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transformando os dados numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35195922, 0.24942792, 1.        , ..., 0.96      , 0.6       ,\n",
       "        0.33333333],\n",
       "       [0.30098447, 0.21281465, 0.9375    , ..., 0.96      , 0.5       ,\n",
       "        0.55555556],\n",
       "       [0.21771275, 1.        , 1.        , ..., 0.84      , 0.4       ,\n",
       "        0.11111111],\n",
       "       ...,\n",
       "       [0.55500214, 0.19450801, 0.8125    , ..., 0.76      , 0.4       ,\n",
       "        0.22222222],\n",
       "       [0.45468695, 0.32494279, 1.        , ..., 0.64      , 0.2       ,\n",
       "        0.33333333],\n",
       "       [0.72162341, 0.21281465, 0.625     , ..., 0.88      , 0.7       ,\n",
       "        0.66666667]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_num_preprocessado = preprocessador_num.transform(dados[dados_numericos])\n",
    "dados_num_preprocessado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adicionando as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Handgrip</th>\n",
       "      <th>BBS</th>\n",
       "      <th>STS</th>\n",
       "      <th>GSST</th>\n",
       "      <th>GSDT</th>\n",
       "      <th>delta GS</th>\n",
       "      <th>DTC</th>\n",
       "      <th>STEP</th>\n",
       "      <th>FMTIT</th>\n",
       "      <th>FMTDT</th>\n",
       "      <th>VF</th>\n",
       "      <th>TMTA</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>DSB</th>\n",
       "      <th>DSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.351959</td>\n",
       "      <td>0.249428</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.664430</td>\n",
       "      <td>0.588886</td>\n",
       "      <td>0.296738</td>\n",
       "      <td>0.339105</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.030101</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.138381</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300984</td>\n",
       "      <td>0.212815</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.648466</td>\n",
       "      <td>0.640657</td>\n",
       "      <td>0.210330</td>\n",
       "      <td>0.251506</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>0.015024</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.172976</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.217713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>0.555078</td>\n",
       "      <td>0.326433</td>\n",
       "      <td>0.371530</td>\n",
       "      <td>0.706349</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.304643</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.312425</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.806099</td>\n",
       "      <td>0.691705</td>\n",
       "      <td>0.339133</td>\n",
       "      <td>0.358881</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.033259</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.206037</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581851</td>\n",
       "      <td>0.409611</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.762922</td>\n",
       "      <td>0.581652</td>\n",
       "      <td>0.427631</td>\n",
       "      <td>0.447559</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.159036</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.288144</td>\n",
       "      <td>0.530892</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.767584</td>\n",
       "      <td>0.405557</td>\n",
       "      <td>0.660269</td>\n",
       "      <td>0.661462</td>\n",
       "      <td>0.531746</td>\n",
       "      <td>0.209267</td>\n",
       "      <td>0.085374</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.373127</td>\n",
       "      <td>0.496568</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.538107</td>\n",
       "      <td>0.247945</td>\n",
       "      <td>0.580085</td>\n",
       "      <td>0.694634</td>\n",
       "      <td>0.420635</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.475828</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.555002</td>\n",
       "      <td>0.194508</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.206131</td>\n",
       "      <td>0.159499</td>\n",
       "      <td>0.284265</td>\n",
       "      <td>0.443175</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.634460</td>\n",
       "      <td>0.887288</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.454687</td>\n",
       "      <td>0.324943</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.635157</td>\n",
       "      <td>0.643512</td>\n",
       "      <td>0.190223</td>\n",
       "      <td>0.231018</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.257731</td>\n",
       "      <td>0.932462</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.116895</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.721623</td>\n",
       "      <td>0.212815</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610890</td>\n",
       "      <td>0.445410</td>\n",
       "      <td>0.415507</td>\n",
       "      <td>0.476207</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.036279</td>\n",
       "      <td>0.104823</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.264612</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Handgrip     BBS       STS      GSST      GSDT  delta GS  \\\n",
       "0    0.351959  0.249428  1.0000  0.647059  0.664430  0.588886  0.296738   \n",
       "1    0.300984  0.212815  0.9375  0.705882  0.648466  0.640657  0.210330   \n",
       "2    0.217713  1.000000  1.0000  0.411765  0.653199  0.555078  0.326433   \n",
       "3    0.312425  0.739130  1.0000  0.705882  0.806099  0.691705  0.339133   \n",
       "4    0.581851  0.409611  0.9375  0.588235  0.762922  0.581652  0.427631   \n",
       "..        ...       ...     ...       ...       ...       ...       ...   \n",
       "104  0.288144  0.530892  0.9375  0.470588  0.767584  0.405557  0.660269   \n",
       "105  0.373127  0.496568  1.0000  0.411765  0.538107  0.247945  0.580085   \n",
       "106  0.555002  0.194508  0.8125  0.058824  0.206131  0.159499  0.284265   \n",
       "107  0.454687  0.324943  1.0000  0.352941  0.635157  0.643512  0.190223   \n",
       "108  0.721623  0.212815  0.6250  0.000000  0.610890  0.445410  0.415507   \n",
       "\n",
       "          DTC      STEP     FMTIT     FMTDT        VF      TMTA  MMSE  DSB  \\\n",
       "0    0.339105  0.619048  0.030101  0.013103  0.444444  0.138381  0.96  0.6   \n",
       "1    0.251506  0.777778  0.044448  0.015024  0.407407  0.172976  0.96  0.5   \n",
       "2    0.371530  0.706349  0.017505  0.006723  0.629630  0.304643  0.84  0.4   \n",
       "3    0.358881  0.936508  0.033259  0.017047  0.814815  0.206037  0.96  0.5   \n",
       "4    0.447559  0.833333  0.005663  0.003121  0.703704  0.159036  0.92  0.8   \n",
       "..        ...       ...       ...       ...       ...       ...   ...  ...   \n",
       "104  0.661462  0.531746  0.209267  0.085374  0.296296  1.000000  0.60  0.3   \n",
       "105  0.694634  0.420635  0.044448  0.091000  0.518519  0.475828  0.68  0.2   \n",
       "106  0.443175  0.309524  0.634460  0.887288  0.259259  1.000000  0.76  0.4   \n",
       "107  0.231018  0.753968  0.257731  0.932462  0.370370  0.116895  0.64  0.2   \n",
       "108  0.476207  0.412698  0.036279  0.104823  0.222222  0.264612  0.88  0.7   \n",
       "\n",
       "          DSF  \n",
       "0    0.333333  \n",
       "1    0.555556  \n",
       "2    0.111111  \n",
       "3    0.111111  \n",
       "4    0.333333  \n",
       "..        ...  \n",
       "104  0.444444  \n",
       "105  0.111111  \n",
       "106  0.222222  \n",
       "107  0.333333  \n",
       "108  0.666667  \n",
       "\n",
       "[109 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_num_preprocessado = pd.DataFrame(dados_num_preprocessado, columns=dados_numericos)\n",
    "dados_num_preprocessado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vamos verificar se estão todos dentro do intervalo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Handgrip</th>\n",
       "      <th>BBS</th>\n",
       "      <th>STS</th>\n",
       "      <th>GSST</th>\n",
       "      <th>GSDT</th>\n",
       "      <th>delta GS</th>\n",
       "      <th>DTC</th>\n",
       "      <th>STEP</th>\n",
       "      <th>FMTIT</th>\n",
       "      <th>FMTDT</th>\n",
       "      <th>VF</th>\n",
       "      <th>TMTA</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>DSB</th>\n",
       "      <th>DSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>109.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.451570</td>\n",
       "      <td>0.266568</td>\n",
       "      <td>0.871560</td>\n",
       "      <td>0.426336</td>\n",
       "      <td>0.590748</td>\n",
       "      <td>0.465977</td>\n",
       "      <td>0.364146</td>\n",
       "      <td>0.433816</td>\n",
       "      <td>0.545435</td>\n",
       "      <td>0.246742</td>\n",
       "      <td>0.265761</td>\n",
       "      <td>0.478337</td>\n",
       "      <td>0.396438</td>\n",
       "      <td>0.787523</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.317901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.232370</td>\n",
       "      <td>0.184651</td>\n",
       "      <td>0.184551</td>\n",
       "      <td>0.185007</td>\n",
       "      <td>0.197322</td>\n",
       "      <td>0.223401</td>\n",
       "      <td>0.171807</td>\n",
       "      <td>0.195413</td>\n",
       "      <td>0.207639</td>\n",
       "      <td>0.318348</td>\n",
       "      <td>0.346636</td>\n",
       "      <td>0.226941</td>\n",
       "      <td>0.286684</td>\n",
       "      <td>0.219946</td>\n",
       "      <td>0.196761</td>\n",
       "      <td>0.235069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.285031</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.463179</td>\n",
       "      <td>0.309254</td>\n",
       "      <td>0.240188</td>\n",
       "      <td>0.305719</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.041737</td>\n",
       "      <td>0.022330</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.191968</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.438577</td>\n",
       "      <td>0.224256</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.602694</td>\n",
       "      <td>0.445410</td>\n",
       "      <td>0.344043</td>\n",
       "      <td>0.439062</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.084057</td>\n",
       "      <td>0.095081</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.295051</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.592902</td>\n",
       "      <td>0.327803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.742171</td>\n",
       "      <td>0.643512</td>\n",
       "      <td>0.464518</td>\n",
       "      <td>0.522522</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.257731</td>\n",
       "      <td>0.389758</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.533828</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age    Handgrip         BBS         STS        GSST        GSDT  \\\n",
       "count  109.000000  100.000000  109.000000  109.000000  109.000000  109.000000   \n",
       "mean     0.451570    0.266568    0.871560    0.426336    0.590748    0.465977   \n",
       "std      0.232370    0.184651    0.184551    0.185007    0.197322    0.223401   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.285031    0.141304    0.812500    0.294118    0.463179    0.309254   \n",
       "50%      0.438577    0.224256    0.937500    0.411765    0.602694    0.445410   \n",
       "75%      0.592902    0.327803    1.000000    0.529412    0.742171    0.643512   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         delta GS         DTC        STEP       FMTIT       FMTDT          VF  \\\n",
       "count  109.000000  109.000000  109.000000  109.000000  109.000000  106.000000   \n",
       "mean     0.364146    0.433816    0.545435    0.246742    0.265761    0.478337   \n",
       "std      0.171807    0.195413    0.207639    0.318348    0.346636    0.226941   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.240188    0.305719    0.412698    0.041737    0.022330    0.296296   \n",
       "50%      0.344043    0.439062    0.547619    0.084057    0.095081    0.481481   \n",
       "75%      0.464518    0.522522    0.698413    0.257731    0.389758    0.629630   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "             TMTA        MMSE         DSB         DSF  \n",
       "count  105.000000  109.000000  108.000000  108.000000  \n",
       "mean     0.396438    0.787523    0.425000    0.317901  \n",
       "std      0.286684    0.219946    0.196761    0.235069  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.191968    0.640000    0.300000    0.111111  \n",
       "50%      0.295051    0.880000    0.400000    0.333333  \n",
       "75%      0.533828    0.960000    0.600000    0.444444  \n",
       "max      1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_num_preprocessado.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podem ver, todos os valores estão entre 0 e 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalonando as variáveis categóricas - One-Hot-Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_1.0</th>\n",
       "      <th>Sex_2.0</th>\n",
       "      <th>Comorbidities_0.0</th>\n",
       "      <th>Comorbidities_1.0</th>\n",
       "      <th>Comorbidities_2.0</th>\n",
       "      <th>Comorbidities_3.0</th>\n",
       "      <th>Comorbidities_4.0</th>\n",
       "      <th>Comorbidities_5.0</th>\n",
       "      <th>Comorbidities_8.0</th>\n",
       "      <th>Scholarity_1.0</th>\n",
       "      <th>Scholarity_2.0</th>\n",
       "      <th>Scholarity_3.0</th>\n",
       "      <th>Scholarity_4.0</th>\n",
       "      <th>IADL_1.0</th>\n",
       "      <th>IADL_2.0</th>\n",
       "      <th>CDT_0.0</th>\n",
       "      <th>CDT_1.0</th>\n",
       "      <th>CDT_2.0</th>\n",
       "      <th>CDT_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_1.0  Sex_2.0  Comorbidities_0.0  Comorbidities_1.0  \\\n",
       "0          1        0                  1                  0   \n",
       "1          1        0                  1                  0   \n",
       "2          0        1                  1                  0   \n",
       "3          0        1                  1                  0   \n",
       "4          0        1                  1                  0   \n",
       "..       ...      ...                ...                ...   \n",
       "104        0        1                  0                  0   \n",
       "105        0        1                  0                  0   \n",
       "106        1        0                  1                  0   \n",
       "107        0        1                  0                  0   \n",
       "108        0        1                  0                  0   \n",
       "\n",
       "     Comorbidities_2.0  Comorbidities_3.0  Comorbidities_4.0  \\\n",
       "0                    0                  0                  0   \n",
       "1                    0                  0                  0   \n",
       "2                    0                  0                  0   \n",
       "3                    0                  0                  0   \n",
       "4                    0                  0                  0   \n",
       "..                 ...                ...                ...   \n",
       "104                  1                  0                  0   \n",
       "105                  1                  0                  0   \n",
       "106                  0                  0                  0   \n",
       "107                  0                  0                  1   \n",
       "108                  0                  0                  0   \n",
       "\n",
       "     Comorbidities_5.0  Comorbidities_8.0  Scholarity_1.0  Scholarity_2.0  \\\n",
       "0                    0                  0               0               0   \n",
       "1                    0                  0               0               0   \n",
       "2                    0                  0               0               0   \n",
       "3                    0                  0               0               0   \n",
       "4                    0                  0               0               0   \n",
       "..                 ...                ...             ...             ...   \n",
       "104                  0                  0               0               0   \n",
       "105                  0                  0               0               1   \n",
       "106                  0                  0               0               1   \n",
       "107                  0                  0               0               0   \n",
       "108                  0                  0               0               0   \n",
       "\n",
       "     Scholarity_3.0  Scholarity_4.0  IADL_1.0  IADL_2.0  CDT_0.0  CDT_1.0  \\\n",
       "0                 0               1         1         0        0        0   \n",
       "1                 1               0         1         0        0        0   \n",
       "2                 1               0         1         0        0        0   \n",
       "3                 0               0         0         1        0        0   \n",
       "4                 0               1         1         0        0        0   \n",
       "..              ...             ...       ...       ...      ...      ...   \n",
       "104               1               0         0         1        1        0   \n",
       "105               0               0         0         1        0        0   \n",
       "106               0               0         0         1        0        1   \n",
       "107               1               0         0         1        0        0   \n",
       "108               1               0         0         1        0        0   \n",
       "\n",
       "     CDT_2.0  CDT_3.0  \n",
       "0          0        1  \n",
       "1          0        1  \n",
       "2          0        1  \n",
       "3          0        1  \n",
       "4          0        1  \n",
       "..       ...      ...  \n",
       "104        0        0  \n",
       "105        1        0  \n",
       "106        0        0  \n",
       "107        1        0  \n",
       "108        0        1  \n",
       "\n",
       "[109 rows x 19 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_cat_preprocessado = pd.get_dummies(dados[dados_categoricos], columns=['Sex', 'Comorbidities', 'Scholarity', 'IADL', 'CDT'])\n",
    "dados_cat_preprocessado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando os valores ausentes nos dados categóricos escalonados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comorbidities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_cat_preprocessado.loc[[57, 58, 60, 68, 69, 70, 77, 78, 93, 108], ['Comorbidities_0.0',\t'Comorbidities_1.0',\t'Comorbidities_2.0',\t'Comorbidities_3.0',\t'Comorbidities_4.0',\t'Comorbidities_5.0',\t'Comorbidities_8.0'\t]] = dados_cat_preprocessado.loc[[57, 58, 60, 68, 69, 70, 77, 78, 93, 108], ['Comorbidities_0.0',\t'Comorbidities_1.0',\t'Comorbidities_2.0',\t'Comorbidities_3.0',\t'Comorbidities_4.0',\t'Comorbidities_5.0',\t'Comorbidities_8.0'\t]].replace(0, np.nan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scholarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_cat_preprocessado.loc[[3, 68, 69, 70], ['Scholarity_1.0',\t'Scholarity_2.0',\t'Scholarity_3.0',\t'Scholarity_4.0']] = dados_cat_preprocessado.loc[[3, 68, 69, 70], ['Scholarity_1.0',\t'Scholarity_2.0',\t'Scholarity_3.0',\t'Scholarity_4.0']].replace(0, np.nan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IADL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_cat_preprocessado.loc[[10, 65, 66, 97], ['IADL_1.0',\t'IADL_2.0']] = dados_cat_preprocessado.loc[[10, 65, 66, 97], ['IADL_1.0',\t'IADL_2.0']].replace(0, np.nan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_cat_preprocessado.loc[[20, 48, 75, 78, 79, 89, 92], ['CDT_0.0',\t'CDT_1.0',\t'CDT_2.0',\t'CDT_3.0']] = dados_cat_preprocessado.loc[[20, 48, 75, 78, 79, 89, 92], ['CDT_0.0',\t'CDT_1.0',\t'CDT_2.0',\t'CDT_3.0']].replace(0, np.nan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropping binary columns duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_cat_preprocessado = dados_cat_preprocessado.drop(['Sex_2.0', 'IADL_2.0'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unindo os dados numéricos e categóricos processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Handgrip</th>\n",
       "      <th>BBS</th>\n",
       "      <th>STS</th>\n",
       "      <th>GSST</th>\n",
       "      <th>GSDT</th>\n",
       "      <th>delta GS</th>\n",
       "      <th>DTC</th>\n",
       "      <th>STEP</th>\n",
       "      <th>FMTIT</th>\n",
       "      <th>FMTDT</th>\n",
       "      <th>VF</th>\n",
       "      <th>TMTA</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>DSB</th>\n",
       "      <th>DSF</th>\n",
       "      <th>Sex_1.0</th>\n",
       "      <th>Comorbidities_0.0</th>\n",
       "      <th>Comorbidities_1.0</th>\n",
       "      <th>Comorbidities_2.0</th>\n",
       "      <th>Comorbidities_3.0</th>\n",
       "      <th>Comorbidities_4.0</th>\n",
       "      <th>Comorbidities_5.0</th>\n",
       "      <th>Comorbidities_8.0</th>\n",
       "      <th>Scholarity_1.0</th>\n",
       "      <th>Scholarity_2.0</th>\n",
       "      <th>Scholarity_3.0</th>\n",
       "      <th>Scholarity_4.0</th>\n",
       "      <th>IADL_1.0</th>\n",
       "      <th>CDT_0.0</th>\n",
       "      <th>CDT_1.0</th>\n",
       "      <th>CDT_2.0</th>\n",
       "      <th>CDT_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.351959</td>\n",
       "      <td>0.249428</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.664430</td>\n",
       "      <td>0.588886</td>\n",
       "      <td>0.296738</td>\n",
       "      <td>0.339105</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.030101</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.138381</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300984</td>\n",
       "      <td>0.212815</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.648466</td>\n",
       "      <td>0.640657</td>\n",
       "      <td>0.210330</td>\n",
       "      <td>0.251506</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>0.015024</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.172976</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.217713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>0.555078</td>\n",
       "      <td>0.326433</td>\n",
       "      <td>0.371530</td>\n",
       "      <td>0.706349</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.304643</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.312425</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.806099</td>\n",
       "      <td>0.691705</td>\n",
       "      <td>0.339133</td>\n",
       "      <td>0.358881</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.033259</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.206037</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581851</td>\n",
       "      <td>0.409611</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.762922</td>\n",
       "      <td>0.581652</td>\n",
       "      <td>0.427631</td>\n",
       "      <td>0.447559</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.159036</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.288144</td>\n",
       "      <td>0.530892</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.767584</td>\n",
       "      <td>0.405557</td>\n",
       "      <td>0.660269</td>\n",
       "      <td>0.661462</td>\n",
       "      <td>0.531746</td>\n",
       "      <td>0.209267</td>\n",
       "      <td>0.085374</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.373127</td>\n",
       "      <td>0.496568</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.538107</td>\n",
       "      <td>0.247945</td>\n",
       "      <td>0.580085</td>\n",
       "      <td>0.694634</td>\n",
       "      <td>0.420635</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.475828</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.555002</td>\n",
       "      <td>0.194508</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.206131</td>\n",
       "      <td>0.159499</td>\n",
       "      <td>0.284265</td>\n",
       "      <td>0.443175</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.634460</td>\n",
       "      <td>0.887288</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.454687</td>\n",
       "      <td>0.324943</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.635157</td>\n",
       "      <td>0.643512</td>\n",
       "      <td>0.190223</td>\n",
       "      <td>0.231018</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.257731</td>\n",
       "      <td>0.932462</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.116895</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.721623</td>\n",
       "      <td>0.212815</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610890</td>\n",
       "      <td>0.445410</td>\n",
       "      <td>0.415507</td>\n",
       "      <td>0.476207</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.036279</td>\n",
       "      <td>0.104823</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.264612</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Handgrip     BBS       STS      GSST      GSDT  delta GS  \\\n",
       "0    0.351959  0.249428  1.0000  0.647059  0.664430  0.588886  0.296738   \n",
       "1    0.300984  0.212815  0.9375  0.705882  0.648466  0.640657  0.210330   \n",
       "2    0.217713  1.000000  1.0000  0.411765  0.653199  0.555078  0.326433   \n",
       "3    0.312425  0.739130  1.0000  0.705882  0.806099  0.691705  0.339133   \n",
       "4    0.581851  0.409611  0.9375  0.588235  0.762922  0.581652  0.427631   \n",
       "..        ...       ...     ...       ...       ...       ...       ...   \n",
       "104  0.288144  0.530892  0.9375  0.470588  0.767584  0.405557  0.660269   \n",
       "105  0.373127  0.496568  1.0000  0.411765  0.538107  0.247945  0.580085   \n",
       "106  0.555002  0.194508  0.8125  0.058824  0.206131  0.159499  0.284265   \n",
       "107  0.454687  0.324943  1.0000  0.352941  0.635157  0.643512  0.190223   \n",
       "108  0.721623  0.212815  0.6250  0.000000  0.610890  0.445410  0.415507   \n",
       "\n",
       "          DTC      STEP     FMTIT     FMTDT        VF      TMTA  MMSE  DSB  \\\n",
       "0    0.339105  0.619048  0.030101  0.013103  0.444444  0.138381  0.96  0.6   \n",
       "1    0.251506  0.777778  0.044448  0.015024  0.407407  0.172976  0.96  0.5   \n",
       "2    0.371530  0.706349  0.017505  0.006723  0.629630  0.304643  0.84  0.4   \n",
       "3    0.358881  0.936508  0.033259  0.017047  0.814815  0.206037  0.96  0.5   \n",
       "4    0.447559  0.833333  0.005663  0.003121  0.703704  0.159036  0.92  0.8   \n",
       "..        ...       ...       ...       ...       ...       ...   ...  ...   \n",
       "104  0.661462  0.531746  0.209267  0.085374  0.296296  1.000000  0.60  0.3   \n",
       "105  0.694634  0.420635  0.044448  0.091000  0.518519  0.475828  0.68  0.2   \n",
       "106  0.443175  0.309524  0.634460  0.887288  0.259259  1.000000  0.76  0.4   \n",
       "107  0.231018  0.753968  0.257731  0.932462  0.370370  0.116895  0.64  0.2   \n",
       "108  0.476207  0.412698  0.036279  0.104823  0.222222  0.264612  0.88  0.7   \n",
       "\n",
       "          DSF  Sex_1.0  Comorbidities_0.0  Comorbidities_1.0  \\\n",
       "0    0.333333        1                1.0                0.0   \n",
       "1    0.555556        1                1.0                0.0   \n",
       "2    0.111111        0                1.0                0.0   \n",
       "3    0.111111        0                1.0                0.0   \n",
       "4    0.333333        0                1.0                0.0   \n",
       "..        ...      ...                ...                ...   \n",
       "104  0.444444        0                0.0                0.0   \n",
       "105  0.111111        0                0.0                0.0   \n",
       "106  0.222222        1                1.0                0.0   \n",
       "107  0.333333        0                0.0                0.0   \n",
       "108  0.666667        0                NaN                NaN   \n",
       "\n",
       "     Comorbidities_2.0  Comorbidities_3.0  Comorbidities_4.0  \\\n",
       "0                  0.0                0.0                0.0   \n",
       "1                  0.0                0.0                0.0   \n",
       "2                  0.0                0.0                0.0   \n",
       "3                  0.0                0.0                0.0   \n",
       "4                  0.0                0.0                0.0   \n",
       "..                 ...                ...                ...   \n",
       "104                1.0                0.0                0.0   \n",
       "105                1.0                0.0                0.0   \n",
       "106                0.0                0.0                0.0   \n",
       "107                0.0                0.0                1.0   \n",
       "108                NaN                NaN                NaN   \n",
       "\n",
       "     Comorbidities_5.0  Comorbidities_8.0  Scholarity_1.0  Scholarity_2.0  \\\n",
       "0                  0.0                0.0             0.0             0.0   \n",
       "1                  0.0                0.0             0.0             0.0   \n",
       "2                  0.0                0.0             0.0             0.0   \n",
       "3                  0.0                0.0             NaN             NaN   \n",
       "4                  0.0                0.0             0.0             0.0   \n",
       "..                 ...                ...             ...             ...   \n",
       "104                0.0                0.0             0.0             0.0   \n",
       "105                0.0                0.0             0.0             1.0   \n",
       "106                0.0                0.0             0.0             1.0   \n",
       "107                0.0                0.0             0.0             0.0   \n",
       "108                NaN                NaN             0.0             0.0   \n",
       "\n",
       "     Scholarity_3.0  Scholarity_4.0  IADL_1.0  CDT_0.0  CDT_1.0  CDT_2.0  \\\n",
       "0               0.0             1.0       1.0      0.0      0.0      0.0   \n",
       "1               1.0             0.0       1.0      0.0      0.0      0.0   \n",
       "2               1.0             0.0       1.0      0.0      0.0      0.0   \n",
       "3               NaN             NaN       0.0      0.0      0.0      0.0   \n",
       "4               0.0             1.0       1.0      0.0      0.0      0.0   \n",
       "..              ...             ...       ...      ...      ...      ...   \n",
       "104             1.0             0.0       0.0      1.0      0.0      0.0   \n",
       "105             0.0             0.0       0.0      0.0      0.0      1.0   \n",
       "106             0.0             0.0       0.0      0.0      1.0      0.0   \n",
       "107             1.0             0.0       0.0      0.0      0.0      1.0   \n",
       "108             1.0             0.0       0.0      0.0      0.0      0.0   \n",
       "\n",
       "     CDT_3.0  \n",
       "0        1.0  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "3        1.0  \n",
       "4        1.0  \n",
       "..       ...  \n",
       "104      0.0  \n",
       "105      0.0  \n",
       "106      0.0  \n",
       "107      0.0  \n",
       "108      1.0  \n",
       "\n",
       "[109 rows x 33 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_processados = pd.merge(dados_num_preprocessado.reset_index(), dados_cat_preprocessado.reset_index())\n",
    "dados_processados = dados_processados.loc[:, 'Age':'CDT_3.0']\n",
    "dados_processados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratando os NaN values\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variável categórica | Linhas c/ NaN values |\n",
    "|----------|--------------------|\n",
    "|Comorbidities | 57, 58, 60, 68, 69, 70, 77, 78, 93, 108 |\n",
    "| IADL | 10, 65, 66, 97 |\n",
    "| Scholarity | 3, 68, 69, 70 |\n",
    "| CDT | 20, 48, 75, 78, 79, 89, 92 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_faltantes = dados.loc[((dados['Scholarity'].isna() == True) | (dados['Comorbidities'].isna() == True) | (dados['Sex'].isna() == True) | (dados['IADL'].isna() == True) | (dados['CDT'].isna() == True) | (dados['Handgrip'].isna() == True) | (dados['TMTA'].isna() == True) | (dados['DSB'].isna() == True) | (dados['DSF'].isna() == True) | (dados['VF'].isna() == True))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Das colunas com valores ausentes temos**:  \n",
    "Comorbidities com 10; int  \n",
    "Scholarity com 4; int  \n",
    "Handgrip com 9; float  \n",
    "IADL com 4; int  \n",
    "CDT com 7; int  \n",
    "TMTA com 4; float  \n",
    "DSF com 1; int  \n",
    "DSB com 1; int  \n",
    "VF com 3. int  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando KNNImputer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gerando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = KNNImputer(weights='distance', n_neighbors= 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ajustando aos dados do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35195922, 0.24942792, 1.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.30098447, 0.21281465, 0.9375    , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.21771275, 1.        , 1.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.55500214, 0.19450801, 0.8125    , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.45468695, 0.32494279, 1.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.72162341, 0.21281465, 0.625     , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meu_array = modelo.fit_transform(dados_processados)\n",
    "meu_array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adicionando colunas ao array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Handgrip</th>\n",
       "      <th>BBS</th>\n",
       "      <th>STS</th>\n",
       "      <th>GSST</th>\n",
       "      <th>GSDT</th>\n",
       "      <th>delta GS</th>\n",
       "      <th>DTC</th>\n",
       "      <th>STEP</th>\n",
       "      <th>FMTIT</th>\n",
       "      <th>FMTDT</th>\n",
       "      <th>VF</th>\n",
       "      <th>TMTA</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>DSB</th>\n",
       "      <th>DSF</th>\n",
       "      <th>Sex_1.0</th>\n",
       "      <th>Comorbidities_0.0</th>\n",
       "      <th>Comorbidities_1.0</th>\n",
       "      <th>Comorbidities_2.0</th>\n",
       "      <th>Comorbidities_3.0</th>\n",
       "      <th>Comorbidities_4.0</th>\n",
       "      <th>Comorbidities_5.0</th>\n",
       "      <th>Comorbidities_8.0</th>\n",
       "      <th>Scholarity_1.0</th>\n",
       "      <th>Scholarity_2.0</th>\n",
       "      <th>Scholarity_3.0</th>\n",
       "      <th>Scholarity_4.0</th>\n",
       "      <th>IADL_1.0</th>\n",
       "      <th>CDT_0.0</th>\n",
       "      <th>CDT_1.0</th>\n",
       "      <th>CDT_2.0</th>\n",
       "      <th>CDT_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.351959</td>\n",
       "      <td>0.249428</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.664430</td>\n",
       "      <td>0.588886</td>\n",
       "      <td>0.296738</td>\n",
       "      <td>0.339105</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.030101</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.138381</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300984</td>\n",
       "      <td>0.212815</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.648466</td>\n",
       "      <td>0.640657</td>\n",
       "      <td>0.210330</td>\n",
       "      <td>0.251506</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>0.015024</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.172976</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.217713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>0.555078</td>\n",
       "      <td>0.326433</td>\n",
       "      <td>0.371530</td>\n",
       "      <td>0.706349</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.304643</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.312425</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.806099</td>\n",
       "      <td>0.691705</td>\n",
       "      <td>0.339133</td>\n",
       "      <td>0.358881</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.033259</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.206037</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581851</td>\n",
       "      <td>0.409611</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.762922</td>\n",
       "      <td>0.581652</td>\n",
       "      <td>0.427631</td>\n",
       "      <td>0.447559</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.159036</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.288144</td>\n",
       "      <td>0.530892</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.767584</td>\n",
       "      <td>0.405557</td>\n",
       "      <td>0.660269</td>\n",
       "      <td>0.661462</td>\n",
       "      <td>0.531746</td>\n",
       "      <td>0.209267</td>\n",
       "      <td>0.085374</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.373127</td>\n",
       "      <td>0.496568</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.538107</td>\n",
       "      <td>0.247945</td>\n",
       "      <td>0.580085</td>\n",
       "      <td>0.694634</td>\n",
       "      <td>0.420635</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.475828</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.555002</td>\n",
       "      <td>0.194508</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.206131</td>\n",
       "      <td>0.159499</td>\n",
       "      <td>0.284265</td>\n",
       "      <td>0.443175</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.634460</td>\n",
       "      <td>0.887288</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.454687</td>\n",
       "      <td>0.324943</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.635157</td>\n",
       "      <td>0.643512</td>\n",
       "      <td>0.190223</td>\n",
       "      <td>0.231018</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.257731</td>\n",
       "      <td>0.932462</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.116895</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.721623</td>\n",
       "      <td>0.212815</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610890</td>\n",
       "      <td>0.445410</td>\n",
       "      <td>0.415507</td>\n",
       "      <td>0.476207</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.036279</td>\n",
       "      <td>0.104823</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.264612</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Handgrip     BBS       STS      GSST      GSDT  delta GS  \\\n",
       "0    0.351959  0.249428  1.0000  0.647059  0.664430  0.588886  0.296738   \n",
       "1    0.300984  0.212815  0.9375  0.705882  0.648466  0.640657  0.210330   \n",
       "2    0.217713  1.000000  1.0000  0.411765  0.653199  0.555078  0.326433   \n",
       "3    0.312425  0.739130  1.0000  0.705882  0.806099  0.691705  0.339133   \n",
       "4    0.581851  0.409611  0.9375  0.588235  0.762922  0.581652  0.427631   \n",
       "..        ...       ...     ...       ...       ...       ...       ...   \n",
       "104  0.288144  0.530892  0.9375  0.470588  0.767584  0.405557  0.660269   \n",
       "105  0.373127  0.496568  1.0000  0.411765  0.538107  0.247945  0.580085   \n",
       "106  0.555002  0.194508  0.8125  0.058824  0.206131  0.159499  0.284265   \n",
       "107  0.454687  0.324943  1.0000  0.352941  0.635157  0.643512  0.190223   \n",
       "108  0.721623  0.212815  0.6250  0.000000  0.610890  0.445410  0.415507   \n",
       "\n",
       "          DTC      STEP     FMTIT     FMTDT        VF      TMTA  MMSE  DSB  \\\n",
       "0    0.339105  0.619048  0.030101  0.013103  0.444444  0.138381  0.96  0.6   \n",
       "1    0.251506  0.777778  0.044448  0.015024  0.407407  0.172976  0.96  0.5   \n",
       "2    0.371530  0.706349  0.017505  0.006723  0.629630  0.304643  0.84  0.4   \n",
       "3    0.358881  0.936508  0.033259  0.017047  0.814815  0.206037  0.96  0.5   \n",
       "4    0.447559  0.833333  0.005663  0.003121  0.703704  0.159036  0.92  0.8   \n",
       "..        ...       ...       ...       ...       ...       ...   ...  ...   \n",
       "104  0.661462  0.531746  0.209267  0.085374  0.296296  1.000000  0.60  0.3   \n",
       "105  0.694634  0.420635  0.044448  0.091000  0.518519  0.475828  0.68  0.2   \n",
       "106  0.443175  0.309524  0.634460  0.887288  0.259259  1.000000  0.76  0.4   \n",
       "107  0.231018  0.753968  0.257731  0.932462  0.370370  0.116895  0.64  0.2   \n",
       "108  0.476207  0.412698  0.036279  0.104823  0.222222  0.264612  0.88  0.7   \n",
       "\n",
       "          DSF  Sex_1.0  Comorbidities_0.0  Comorbidities_1.0  \\\n",
       "0    0.333333      1.0                1.0                0.0   \n",
       "1    0.555556      1.0                1.0                0.0   \n",
       "2    0.111111      0.0                1.0                0.0   \n",
       "3    0.111111      0.0                1.0                0.0   \n",
       "4    0.333333      0.0                1.0                0.0   \n",
       "..        ...      ...                ...                ...   \n",
       "104  0.444444      0.0                0.0                0.0   \n",
       "105  0.111111      0.0                0.0                0.0   \n",
       "106  0.222222      1.0                1.0                0.0   \n",
       "107  0.333333      0.0                0.0                0.0   \n",
       "108  0.666667      0.0                0.0                0.0   \n",
       "\n",
       "     Comorbidities_2.0  Comorbidities_3.0  Comorbidities_4.0  \\\n",
       "0                  0.0                0.0                0.0   \n",
       "1                  0.0                0.0                0.0   \n",
       "2                  0.0                0.0                0.0   \n",
       "3                  0.0                0.0                0.0   \n",
       "4                  0.0                0.0                0.0   \n",
       "..                 ...                ...                ...   \n",
       "104                1.0                0.0                0.0   \n",
       "105                1.0                0.0                0.0   \n",
       "106                0.0                0.0                0.0   \n",
       "107                0.0                0.0                1.0   \n",
       "108                1.0                0.0                0.0   \n",
       "\n",
       "     Comorbidities_5.0  Comorbidities_8.0  Scholarity_1.0  Scholarity_2.0  \\\n",
       "0                  0.0                0.0             0.0             0.0   \n",
       "1                  0.0                0.0             0.0             0.0   \n",
       "2                  0.0                0.0             0.0             0.0   \n",
       "3                  0.0                0.0             0.0             0.0   \n",
       "4                  0.0                0.0             0.0             0.0   \n",
       "..                 ...                ...             ...             ...   \n",
       "104                0.0                0.0             0.0             0.0   \n",
       "105                0.0                0.0             0.0             1.0   \n",
       "106                0.0                0.0             0.0             1.0   \n",
       "107                0.0                0.0             0.0             0.0   \n",
       "108                0.0                0.0             0.0             0.0   \n",
       "\n",
       "     Scholarity_3.0  Scholarity_4.0  IADL_1.0  CDT_0.0  CDT_1.0  CDT_2.0  \\\n",
       "0               0.0             1.0       1.0      0.0      0.0      0.0   \n",
       "1               1.0             0.0       1.0      0.0      0.0      0.0   \n",
       "2               1.0             0.0       1.0      0.0      0.0      0.0   \n",
       "3               1.0             0.0       0.0      0.0      0.0      0.0   \n",
       "4               0.0             1.0       1.0      0.0      0.0      0.0   \n",
       "..              ...             ...       ...      ...      ...      ...   \n",
       "104             1.0             0.0       0.0      1.0      0.0      0.0   \n",
       "105             0.0             0.0       0.0      0.0      0.0      1.0   \n",
       "106             0.0             0.0       0.0      0.0      1.0      0.0   \n",
       "107             1.0             0.0       0.0      0.0      0.0      1.0   \n",
       "108             1.0             0.0       0.0      0.0      0.0      0.0   \n",
       "\n",
       "     CDT_3.0  \n",
       "0        1.0  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "3        1.0  \n",
       "4        1.0  \n",
       "..       ...  \n",
       "104      0.0  \n",
       "105      0.0  \n",
       "106      0.0  \n",
       "107      0.0  \n",
       "108      1.0  \n",
       "\n",
       "[109 rows x 33 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_preenchidos = pd.DataFrame(meu_array, columns = dados_processados.columns)\n",
    "dados_preenchidos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O código abaixo mostra se há dados ausentes nas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                  0\n",
       "Handgrip             0\n",
       "BBS                  0\n",
       "STS                  0\n",
       "GSST                 0\n",
       "GSDT                 0\n",
       "delta GS             0\n",
       "DTC                  0\n",
       "STEP                 0\n",
       "FMTIT                0\n",
       "FMTDT                0\n",
       "VF                   0\n",
       "TMTA                 0\n",
       "MMSE                 0\n",
       "DSB                  0\n",
       "DSF                  0\n",
       "Sex_1.0              0\n",
       "Comorbidities_0.0    0\n",
       "Comorbidities_1.0    0\n",
       "Comorbidities_2.0    0\n",
       "Comorbidities_3.0    0\n",
       "Comorbidities_4.0    0\n",
       "Comorbidities_5.0    0\n",
       "Comorbidities_8.0    0\n",
       "Scholarity_1.0       0\n",
       "Scholarity_2.0       0\n",
       "Scholarity_3.0       0\n",
       "Scholarity_4.0       0\n",
       "IADL_1.0             0\n",
       "CDT_0.0              0\n",
       "CDT_1.0              0\n",
       "CDT_2.0              0\n",
       "CDT_3.0              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_preenchidos.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nesta etapa, nosso maior objetivo é descobri qual é a variável mais importante.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separando os dados originais, ou seja, sem manipulação de técnicas de preenchimento dos dados sintéticos, ou seja, onde houve manipulação de técnicas de preenchimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_true_nan = dados.isna().apply(lambda x: x.sum(), axis=1) > 0 \n",
    "dados_validos = dados_preenchidos[~list_true_nan]\n",
    "dados_nan =  dados_preenchidos[list_true_nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Se 80% for pra teste terísmos 87 dados sem separação\n",
    "2. Se 70% dos dados válidos forem pro treino + 31 dos dados nan teremos 86 dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78, 33), (31, 33))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_validos.shape, dados_nan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separando nosso dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separando Dados válidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino_val, X_validador, y_treino_val, y_validador = train_test_split(dados_validos, dados.loc[~list_true_nan, 'Diagnoses'], test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agregando os dados preenchidos ao treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54, 33), (31, 33))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treino_val.shape, dados_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85, 33), (85,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treino = pd.concat([X_treino_val, dados_nan], axis=0)\n",
    "y_treino = pd.concat([y_treino_val, dados.loc[list_true_nan, 'Diagnoses']])\n",
    "X_treino.shape, y_treino.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Feature Importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gerando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_tree = RandomForestClassifier(random_state=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Otimizando hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_parametros = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [4,5,6,7,8],\n",
    "    'max_features': [3, 6, 12, 18, 24],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.67058824 0.64705882 0.67058824        nan 0.65882353 0.65882353\n",
      "        nan 0.63529412        nan        nan        nan        nan\n",
      " 0.64705882 0.67058824 0.64705882 0.64705882        nan 0.65882353\n",
      " 0.65882353 0.68235294 0.64705882        nan        nan 0.68235294\n",
      " 0.64705882        nan        nan        nan 0.65882353 0.67058824\n",
      "        nan 0.67058824 0.64705882        nan        nan 0.67058824\n",
      " 0.64705882        nan 0.63529412        nan 0.65882353 0.65882353\n",
      " 0.65882353        nan 0.65882353 0.68235294 0.65882353 0.64705882\n",
      " 0.67058824 0.67058824 0.67058824 0.68235294 0.67058824 0.67058824\n",
      " 0.64705882        nan 0.67058824 0.65882353 0.67058824 0.67058824\n",
      " 0.67058824 0.63529412 0.68235294 0.69411765 0.65882353 0.67058824\n",
      "        nan 0.65882353        nan 0.64705882        nan 0.68235294\n",
      " 0.65882353        nan 0.65882353 0.63529412        nan 0.65882353\n",
      "        nan        nan 0.68235294 0.67058824 0.65882353        nan\n",
      "        nan 0.67058824 0.65882353        nan        nan 0.67058824\n",
      " 0.67058824 0.65882353        nan        nan        nan        nan\n",
      " 0.65882353 0.65882353        nan 0.64705882 0.68235294 0.67058824\n",
      " 0.65882353 0.67058824 0.65882353 0.68235294 0.67058824 0.65882353\n",
      " 0.67058824        nan 0.68235294        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gs = RandomizedSearchCV(\n",
    "    estimator=modelo_tree,\n",
    "    param_distributions=dicionario_parametros,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_iter=112\n",
    ").fit(X_treino, y_treino)\n",
    "# 43 minutos rodando"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verificando o melhores parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500, 'max_features': 6, 'max_depth': 7, 'criterion': 'gini'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aplicando o modelo com os parâmetros tunados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_tree = RandomForestClassifier(random_state=4, criterion='gini', max_depth=7, n_estimators=500, max_features=6 ).fit(X_treino, y_treino)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verificando a acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_tree.score(X_validador, y_validador) # O R² do modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plotando a matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = modelo_tree.predict(X_validador)\n",
    "cm = confusion_matrix(y_validador, predictions, labels=modelo_tree.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=modelo_tree.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exibindo as métricas de exatidão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.78      0.78      0.78         9\n",
      "         2.0       1.00      0.60      0.75         5\n",
      "         3.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        24\n",
      "   macro avg       0.87      0.79      0.81        24\n",
      "weighted avg       0.85      0.83      0.83        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validador, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando quais são as variáveis mais relevantes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recebendo os resultados da feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMSE, 0.12248126696683766\n",
      "FMTIT, 0.10806435943148192\n",
      "FMTDT, 0.0946737680594306\n",
      "VF, 0.0872582114414557\n",
      "GSDT, 0.06552438825395189\n",
      "GSST, 0.05305893332143734\n",
      "STEP, 0.041763813733543036\n",
      "IADL_1.0, 0.04028509588811785\n",
      "TMTA, 0.038203383632849516\n",
      "Age, 0.037988803440566585\n",
      "DTC, 0.03709895189783781\n",
      "STS, 0.03301609148026862\n",
      "Handgrip, 0.03131215870226896\n",
      "delta GS, 0.029192330064561005\n",
      "BBS, 0.02811471902564555\n",
      "CDT_3.0, 0.0274012756678396\n",
      "DSB, 0.027199908903077604\n",
      "DSF, 0.01785809106428951\n",
      "Comorbidities_1.0, 0.01213997485452766\n",
      "Comorbidities_3.0, 0.009517683999291272\n",
      "Sex_1.0, 0.008392315571995742\n",
      "CDT_0.0, 0.007602238563039741\n",
      "CDT_2.0, 0.007245318944399111\n",
      "CDT_1.0, 0.00679394288751847\n",
      "Scholarity_4.0, 0.005647287982842171\n",
      "Comorbidities_4.0, 0.005574927480811126\n",
      "Scholarity_2.0, 0.0036191498801735836\n",
      "Comorbidities_0.0, 0.0035346070225142174\n",
      "Comorbidities_2.0, 0.003397386067444725\n",
      "Scholarity_1.0, 0.0030951714675854724\n",
      "Scholarity_3.0, 0.0029444443023960228\n",
      "Comorbidities_8.0, 0.0\n",
      "Comorbidities_5.0, 0.0\n"
     ]
    }
   ],
   "source": [
    "importances = modelo_tree.feature_importances_\n",
    "\n",
    "indices_ordenados = np.argsort(importances)[::-1]\n",
    "\n",
    "for i in range(X_validador.shape[1]):\n",
    "    print(f'{X_validador.columns[indices_ordenados[i]]}, {importances[indices_ordenados[i]]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plotando o gráfico das pontuações das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.title('Feature Importance')\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.bar(range(X_validador.shape[1]), importances[indices_ordenados], align='center')\n",
    "plt.xticks(range(X_validador.shape[1]), X_treino.columns[indices_ordenados], rotation=90)\n",
    "plt.savefig('Feature_importance.jpeg')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizando a árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "_= tree.plot_tree(\n",
    "    modelo_tree.estimators_[2],\n",
    "    feature_names = X_validador.columns,\n",
    "    class_names = 'Diagnoses',\n",
    "    filled=True,\n",
    "    rounded=True\n",
    ")\n",
    "# plt.savefig('Arvore_decisao.jpeg')\n",
    "# len(modelo_tree.estimators_) # Nº de árvores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33f60ada2f0aff3080e0360b5db9e96f3b69d573130485e475b6fee33ea624aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
